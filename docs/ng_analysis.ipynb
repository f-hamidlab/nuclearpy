{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3359d7fe",
   "metadata": {},
   "source": [
    "# Nuclear Game - Analysis\n",
    "Gabriel Emilio Herrera Oropeza <br>\n",
    "13/06/2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18228144",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import anndata\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join, isdir\n",
    "import statistics\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "import scanpy as sc\n",
    "from math import log10\n",
    "from skimage.filters import threshold_otsu, threshold_triangle\n",
    "from statannotations.Annotator import Annotator\n",
    "from skimage.filters import threshold_multiotsu\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n",
    "from PIL import Image, ImageEnhance\n",
    "import plotly.graph_objects as go\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sc.settings.verbosity = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b343f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _log(txt, verbose = True):\n",
    "    if verbose:\n",
    "        print(txt)\n",
    "        \n",
    "        \n",
    "def intensityNormalisation(df, method = \"mode\", nbins = 10, verbose = True, hue = \"experiment\"):\n",
    "    dct_norm = {}\n",
    "    df_ = df.copy()\n",
    "    method = method.lower()\n",
    "    for n, exp in tqdm(enumerate(set(df_[hue])), total = len(set(df_[hue]))):\n",
    "        subset = df_[df_[hue] == exp]\n",
    "        dct_norm[exp] = {}\n",
    "        for col in subset.columns:\n",
    "            if \"avg_intensity\" in col and not any(l in col.lower() for l in [\"dapi\", \"gfap\", \"olig2\"]):\n",
    "                if method == \"mode\":\n",
    "                    relevant_subset = subset[[col]].copy()\n",
    "                    relevant_subset[\"bins\"] = pd.cut(relevant_subset[col], nbins, duplicates = \"drop\", \n",
    "                                                      labels = False)\n",
    "                    bins_mode = statistics.mode(relevant_subset[\"bins\"])\n",
    "                    mode_ = relevant_subset[col][relevant_subset[\"bins\"] == bins_mode].median()\n",
    "                    subset[col] = subset[col] / mode_\n",
    "                    dct_norm[exp][col] = mode_\n",
    "                    _log(f\"Reference value for {col} in {exp}: {mode_}\", verbose)\n",
    "                elif method == \"mean\":\n",
    "                    mean_ = subset[col].mean()\n",
    "                    subset[col] = subset[col] / mean_\n",
    "                    dct_norm[exp][col] = mean_\n",
    "                elif method == \"median\":\n",
    "                    median_ = subset[col].median()\n",
    "                    subset[col] = subset[col] / median_\n",
    "                    dct_norm[exp][col] = median_\n",
    "        if n == 0:\n",
    "            out_df = subset.copy()\n",
    "        else:\n",
    "            out_df = out_df.append(subset)\n",
    "    return out_df, dct_norm\n",
    "\n",
    "\n",
    "def find_SingleCells(df, byExperiment = True, nbins = 10, spread = 0.2, channel = \"dapi\", hue = \"experiment\"):\n",
    "    df_ = df.copy()\n",
    "    dct_norm = {}\n",
    "    col = f\"total_intensity_{channel}\"\n",
    "    \n",
    "    if not col in list(df_.columns):\n",
    "        raise ValueError(\"Ops! Channel not found.\")\n",
    "    \n",
    "    if byExperiment:\n",
    "        for n, exp in tqdm(enumerate(set(df_[hue])), total = len(set(df_[hue]))):\n",
    "            subset = df_[df_[hue] == exp]\n",
    "            temp = subset.copy()\n",
    "            temp[\"bins\"] = pd.cut(temp[col], nbins, duplicates = \"drop\", labels = False)\n",
    "            bins_mode = statistics.mode(temp[\"bins\"])\n",
    "            mode_ = temp[col][temp[\"bins\"] == bins_mode].median()\n",
    "            subset[col] = subset[col] / mode_\n",
    "            dct_norm[exp] = mode_\n",
    "            if n == 0:\n",
    "                out_df = subset.copy()\n",
    "            else:\n",
    "                out_df = out_df.append(subset)\n",
    "    elif not byExperiment:\n",
    "        temp = df_.copy()\n",
    "        temp[\"bins\"] = pd.cut(temp[col], nbins, duplicates = \"drop\", labels = False)\n",
    "        bins_mode = statistics.mode(temp[\"bins\"])\n",
    "        mode_ = temp[col][temp[\"bins\"] == bins_mode].median()\n",
    "        df_[col] = df_[col] / mode_\n",
    "        dct_norm[\"all\"] = mode_\n",
    "        out_df = df_.copy()\n",
    "                \n",
    "    out_df[\"isSingleCell\"] = [True if row[col] >= 1-spread and row[col] <= 1+spread else False \n",
    "                              for index, row in out_df.iterrows()]\n",
    "    \n",
    "    return out_df\n",
    "\n",
    "\n",
    "def generatePairs(data):\n",
    "    if not isinstance(data, list):\n",
    "        try:\n",
    "            data = list(data)\n",
    "        except:\n",
    "            raise ValueError(\"Input should be list or vector.\")\n",
    "    res = [(a, b) for idx, a in enumerate(data) for b in data[idx + 1:]]\n",
    "    return res\n",
    "\n",
    "\n",
    "def _normalise_data(X, method = \"standardscaler\", copy = False):\n",
    "\n",
    "    X = X.copy() if copy else X\n",
    "    \n",
    "    if method.lower() == \"standardscaler\":\n",
    "        X = StandardScaler().fit_transform(X)\n",
    "    elif method.lower() == \"minmaxscaler\":\n",
    "        X = MinMaxScaler().fit_transform(X)\n",
    "    elif method.lower() == \"maxabsscaler\":\n",
    "        X = MaxAbsScaler().fit_transform(X)\n",
    "    else:\n",
    "        pass\n",
    "       # logg.info(f\"Method '{method}' not supported. Data was not normalised.\")\n",
    "    \n",
    "    return X\n",
    "\n",
    "\n",
    "def show_cell(data, order_by = \"areaNucleus\", fig_height = 15, fig_width = 40, show_nucleus = True,\n",
    "              contrast_red = 3, contrast_green = 3, contrast_blue = 4, uniqID = False, channels = [\"var\", \"rfp\", \"beta3\"]):\n",
    "    df = data.copy()\n",
    "    \n",
    "    # Ask for the number of cells to show\n",
    "    while True:\n",
    "        no_cells = input('\\nEnter number of nuclei to show (any integer OR \"all\"): ')\n",
    "        try:\n",
    "            no_cells = int(no_cells)\n",
    "            break\n",
    "        except:\n",
    "            if isinstance(no_cells, str):\n",
    "                if no_cells.lower() == 'all':\n",
    "                    no_cells = len(df)\n",
    "                    break\n",
    "            else:\n",
    "                print('Ops! Invalid number format! Enter an integer or \"all\"')\n",
    "\n",
    "\n",
    "    if len(df) == no_cells:\n",
    "        print(f\"\\nShowing all cells ({len(df)}) in the selected area\")\n",
    "\n",
    "    if len(df) > no_cells:\n",
    "        print('\\nShowing {0} cells of a total of {1} in the selected data'.format(no_cells, str(len(df))))\n",
    "\n",
    "    if len(df) < no_cells:\n",
    "        no_cells = len(df)\n",
    "        print('\\nONLY ' + str(len(df)) + ' cells were found in the selected data')\n",
    "\n",
    "    new_df = df.sample(n = no_cells)\n",
    "\n",
    "    # Get the names of the channels\n",
    "    dct_channels = {}\n",
    "\n",
    "    for ch in channels:\n",
    "        dct_channels[ch] = input(f'Show {ch} (y/n): ')\n",
    "\n",
    "    # Color of the channels\n",
    "    dct_colors = {}\n",
    "\n",
    "    for ch in dct_channels:\n",
    "        if dct_channels[ch].lower() == 'y':\n",
    "            while True:\n",
    "                try:\n",
    "                    dct_colors[ch] = input('Desired colour for {0} (red/green/blue): '.format(ch))\n",
    "                    if dct_colors[ch] == 'red' or dct_colors[ch] == 'green' or dct_colors[ch] == 'blue':\n",
    "                        break\n",
    "                    else:\n",
    "                        raise ValueError\n",
    "                except:\n",
    "                    print('Input color {0} is not valid!'.format(dct_colors[ch]))\n",
    "                    pass\n",
    "\n",
    "    # Generate the figure\n",
    "    if no_cells <= 5:\n",
    "        fig, axes = plt.subplots(nrows = no_cells, ncols = 1, sharex = True, sharey = True,\n",
    "                                 figsize = (int(fig_width)/2.54, (int(fig_height)/2.54) * no_cells))\n",
    "    elif no_cells > 5 and no_cells <= 10:\n",
    "        fig, axes = plt.subplots(nrows = 2, ncols = 5, sharex = True, sharey = True,\n",
    "                                figsize = (int(fig_width)/2.54, (int(fig_height)/2.54)))\n",
    "    elif no_cells > 10:\n",
    "        if int(str(no_cells)[-1]) > 5:\n",
    "            fig, axes = plt.subplots(nrows = ((no_cells // 5) + 1), ncols = 5, sharex = True, sharey = True,\n",
    "                                    figsize = (int(fig_width)/2.54, (int(fig_height)/2.54) * ((no_cells // 10) + 1)))\n",
    "        elif int(str(no_cells)[-1]) <= 5 and int(str(no_cells)[-1]) > 0:\n",
    "            fig, axes = plt.subplots(nrows = (no_cells // 5 + 1), ncols = 5, sharex = True, sharey = True,\n",
    "                                    figsize = (int(fig_width)/2.54, (int(fig_height)/2.54) * ((no_cells // 10) + 0.5)))\n",
    "        elif int(str(no_cells)[-1]) == 0:\n",
    "            fig, axes = plt.subplots(nrows = (no_cells // 5), ncols = 5, sharex = True, sharey = True,\n",
    "                                    figsize = (int(fig_width)/2.54, (int(fig_height)/2.54) * (no_cells // 10)))\n",
    "\n",
    "    ax = axes.ravel()\n",
    "\n",
    "    # Create Unique ID dictionary\n",
    "    if uniqID:\n",
    "        uniqID_dct = {}\n",
    "\n",
    "    n = 0\n",
    "    for index, row in tqdm(new_df.iterrows(), total = new_df.shape[0]):\n",
    "        masks = np.load(join(row[\"path2ong\"].replace(\"output.csv\", \"\"), row[\"imageID\"], f\"{row['imageID']}_masks.npy\"))\n",
    "        wk_array = np.load(join(row[\"path2ong\"].replace(\"output.csv\", \"\"), row[\"imageID\"], f\"{row['imageID']}_wkarray.npy\"))\n",
    "        nucleus = wk_array[0].copy()\n",
    "        nucleus[masks != row['cellID']] = 0\n",
    "        cX_low, cX_high, cY_low, cY_high = zoomIN(nucleus, row[\"x_pos\"], row[\"y_pos\"], zoom_box_side = 300)\n",
    "        nucleus = nucleus[cY_low:cY_high, cX_low:cX_high]\n",
    "        y, x = nucleus.shape\n",
    "        color_red = Image.fromarray(np.zeros((y, x, 3), dtype = 'uint8')).convert('L')\n",
    "        color_green = Image.fromarray(np.zeros((y, x, 3), dtype = 'uint8')).convert('L')\n",
    "        color_blue = Image.fromarray(np.zeros((y, x, 3), dtype = 'uint8')).convert('L')\n",
    "        for ch in dct_channels:\n",
    "            if dct_channels[ch].lower() == 'y':\n",
    "                channel = wk_array[channels.index(ch) + 1].copy()\n",
    "                channel = channel[cY_low:cY_high, cX_low:cX_high]\n",
    "                channel = cv2.normalize(channel, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "                RGB = np.array((*\"RGB\",))\n",
    "                if dct_colors[ch].lower() == 'red':\n",
    "                    color = np.multiply.outer(channel, RGB == 'R')\n",
    "                    color_red = Image.fromarray(color).convert('L')\n",
    "                    enhancer = ImageEnhance.Contrast(color_red)\n",
    "                    color_red = enhancer.enhance(contrast_red)\n",
    "                elif dct_colors[ch].lower() == 'green':\n",
    "                    color = np.multiply.outer(channel, RGB == 'G')\n",
    "                    color_green = Image.fromarray(color).convert('L')\n",
    "                    enhancer = ImageEnhance.Contrast(color_green)\n",
    "                    color_green = enhancer.enhance(contrast_green)\n",
    "                elif dct_colors[ch].lower() == 'blue':\n",
    "                    color = np.multiply.outer(channel, RGB == 'B')\n",
    "                    color_blue = Image.fromarray(color).convert('L')\n",
    "                    enhancer = ImageEnhance.Contrast(color_blue)\n",
    "                    color_blue = enhancer.enhance(contrast_blue)\n",
    "        mrg = Image.merge(\"RGB\", (color_red, color_green, color_blue))\n",
    "        mrg = np.array(mrg, dtype = 'uint8')\n",
    "        scalebar = ScaleBar(0.227, 'um', box_alpha = 0, location = \"upper left\", color = \"w\") # 1 pixel = 1um\n",
    "        if show_nucleus == False:\n",
    "            kernel = np.ones((3, 3), np.uint8)\n",
    "            masks[masks != int(row['cellID'])] = 0\n",
    "            masks[masks == int(row['cellID'])] = 1\n",
    "            masks = masks[cY_low:cY_high, cX_low:cX_high]\n",
    "            masks = np.uint16(masks)\n",
    "            eroded = cv2.erode(masks, kernel, iterations = 2)\n",
    "            nucleus = masks - eroded\n",
    "            nucleus = np.array(nucleus, dtype = 'uint8')\n",
    "            mrg[nucleus == 1] = [255, 255, 255]\n",
    "            ax[n].set_xlim(0,299)\n",
    "            ax[n].set_ylim(299,0)\n",
    "            ax[n].imshow(mrg)\n",
    "            ax[n].add_artist(scalebar)\n",
    "        if show_nucleus == True:\n",
    "            nucleus = np.ma.masked_where(nucleus == 0, nucleus)\n",
    "            ax[n].set_xlim(0,299)\n",
    "            ax[n].set_ylim(299,0)\n",
    "            ax[n].imshow(mrg)\n",
    "            ax[n].imshow(nucleus)\n",
    "            ax[n].add_artist(scalebar)\n",
    "        if uniqID:\n",
    "            ax[n].set_title(f\"ID: {n+1}\", fontdict = {'fontsize' : 8})\n",
    "            uniqID_dct[str(n+1)] = {\"cellID\": row[\"cellID\"], \"imageID\": row[\"imageID\"]}\n",
    "        else:\n",
    "            ax[n].set_title(f\"{row['imageID']} | {row['cellID']}\", fontdict = {'fontsize' : 8})\n",
    "        ax[n].axis(\"off\")\n",
    "        n += 1\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if uniqID:\n",
    "        return fig, uniqID_dct\n",
    "    else:\n",
    "        return fig\n",
    "    \n",
    "    \n",
    "def zoomIN(nucleus, x_pos, y_pos, zoom_box_side = 300):\n",
    "    zoom_box_side = zoom_box_side / 2\n",
    "    cY = int(y_pos)\n",
    "    cX = int(x_pos)\n",
    "    cY_low = cY - zoom_box_side\n",
    "    cY_high = cY + zoom_box_side\n",
    "    cX_low = cX - zoom_box_side\n",
    "    cX_high = cX + zoom_box_side\n",
    "    if (cY-zoom_box_side) < 0:\n",
    "        cY_low = 0\n",
    "    if (cY+zoom_box_side) > len(nucleus):\n",
    "        cY_high = len(nucleus)\n",
    "    if (cX-zoom_box_side) < 0:\n",
    "        cX_low = 0\n",
    "    if (cX+zoom_box_side) > len(nucleus[0]):\n",
    "        cX_high = len(nucleus[0])\n",
    "    return int(cX_low), int(cX_high), int(cY_low), int(cY_high)\n",
    "\n",
    "\n",
    "def embeddingPlotter(adata, basis = \"umap\", size = 20):\n",
    "    \n",
    "    df = adata.obs.copy()\n",
    "    df = df.reset_index(drop = True)\n",
    "    \n",
    "    if basis == \"diffmap\":\n",
    "        \n",
    "        df[\"x\"] = adata.obsm[\"X_diffmap\"][..., 1]\n",
    "        df[\"y\"] = adata.obsm[\"X_diffmap\"][..., 2]\n",
    "        \n",
    "    f = go.FigureWidget([go.Scatter(y = df[\"y\"],\n",
    "                                x = df[\"x\"],\n",
    "                                mode = 'markers',\n",
    "                                marker=dict(size = size\n",
    "                                            )\n",
    "                                )\n",
    "                     ]\n",
    "                    )\n",
    "\n",
    "    scatter = f.data[0]\n",
    "\n",
    "    t = go.FigureWidget([go.Table(\n",
    "    header=dict(values = df.columns,\n",
    "                fill = dict(color='#C2D4FF'),\n",
    "                align = ['left'] * 5),\n",
    "    cells=dict(values=[df[col].to_list() for col in df.columns],\n",
    "               fill = dict(color='#F5F8FF'),\n",
    "               align = ['left'] * 5))])\n",
    "\n",
    "    def selection_fn(trace,points,selector):\n",
    "        t.data[0].cells.values = [df.reindex(index = points.point_inds)[col] for col in df.columns]\n",
    "\n",
    "    scatter.on_selection(selection_fn)\n",
    "\n",
    "    return f, t\n",
    "    \n",
    "    \n",
    "def selection2df(table):\n",
    "\n",
    "    d = table.to_dict()\n",
    "    df_out = pd.DataFrame(d['data'][0]['cells']['values'], index = d['data'][0]['header']['values']).T\n",
    "    df_out = df_out.reset_index(drop = True)\n",
    "    return df_out\n",
    "\n",
    "\n",
    "def centerDAPI(data, splitBy = \"experiment\", nbins = 100, showPlot = True):\n",
    "    \n",
    "    modes_ = {}\n",
    "    for exp in data[splitBy].unique():\n",
    "        subset = data[data[splitBy] == exp]\n",
    "        subset[\"bins\"] = pd.cut(subset[\"total_intensity_dapi\"], nbins, duplicates = \"drop\", labels = False)\n",
    "        bins_mode = statistics.mode(subset[\"bins\"])\n",
    "        mode_ = subset[\"total_intensity_dapi\"][subset[\"bins\"] == bins_mode].median()\n",
    "        modes_[exp] = mode_\n",
    "        \n",
    "    dapi_reference = data[\"total_intensity_dapi\"].median()\n",
    "    \n",
    "    dapi_norm = {}\n",
    "    for k, v in modes_.items():\n",
    "        dapi_norm[k] = dapi_reference / v\n",
    "        \n",
    "    data[\"avg_intensity_dapi\"] = [row[\"avg_intensity_dapi\"] * dapi_norm[row[\"experiment\"]] for index, row in data.iterrows()]\n",
    "    \n",
    "    if showPlot:\n",
    "        fig, ax = plt.subplots(figsize = (3*len(data[splitBy].unique()),6))\n",
    "        sns.violinplot(x = splitBy, y = \"total_intensity_dapi\", data = data, ax = ax)\n",
    "        for n, exp in enumerate(data[splitBy].unique()):\n",
    "            X = n\n",
    "            ax.plot([X-0.4,X+0.4], [modes_[exp],modes_[exp]], color = 'r')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2501c836",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "### Select Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9daaa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_experiments = \"E:/emilio/phd/NucleusAnalysis/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc9350a",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [exp for exp in listdir(path_to_experiments) if isdir(join(path_to_experiments, exp))]\n",
    "print(\"Experiments in current directory:\\n\")\n",
    "for exp in experiments:\n",
    "    print(f\"\\t{exp}\")\n",
    "\n",
    "while True:\n",
    "    experiment = input(\"\\nEnter one of the experiments above: \")\n",
    "    if experiment in experiments:\n",
    "        break\n",
    "    else:\n",
    "        print(\"Experiment entered NOT in list of experiments available. Try again...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ba2991",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abba3963",
   "metadata": {},
   "outputs": [],
   "source": [
    "within_experiment = [file for file in listdir(join(path_to_experiments, experiment)) \n",
    "                     if isdir(join(path_to_experiments, experiment, file))]\n",
    "\n",
    "for n, file in enumerate(within_experiment):\n",
    "    if n == 0:\n",
    "        data = pd.read_csv(join(path_to_experiments, experiment, file, \"out_ng\", \"output.csv\"))\n",
    "        data[\"experiment\"] = file\n",
    "    else:\n",
    "        temp = pd.read_csv(join(path_to_experiments, experiment, file, \"out_ng\", \"output.csv\"))\n",
    "        temp[\"experiment\"] = file\n",
    "        data = data.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97e6455",
   "metadata": {},
   "source": [
    "### Center DAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f603f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = centerDAPI(data, splitBy = \"experiment\", nbins = 100, showPlot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ee9eaa",
   "metadata": {},
   "source": [
    "### Identify Single Cells\n",
    "Identify single cells based on DNA marker content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6a2d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scData = find_SingleCells(data, byExperiment = True, nbins = 100, spread = 0.4, channel = \"dapi\", hue = \"experiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa57929c",
   "metadata": {},
   "source": [
    "Check selection of single cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1719e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (6.4, 4.8))\n",
    "ax = sns.scatterplot(data = scData, y = \"avg_intensity_dapi\", x = \"nuclear_area\", hue = \"isSingleCell\", alpha = 0.5,\n",
    "                    ax = ax)\n",
    "ax.set(xscale = \"log\"); ax.set(yscale = \"log\"); plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525450a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only single cells\n",
    "scData = scData[scData[\"isSingleCell\"] == True].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bd0e88",
   "metadata": {},
   "source": [
    "### Intensity Normalisation\n",
    "Statistic-based normalisation of intensity data. **Options are: mode, mean, and median.** *nbins* is used only when method is *mode*. DAPI channel is not normalised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db3aa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "normData, normMetadata = intensityNormalisation(scData, method = \"mode\", nbins = 100, verbose = False, \n",
    "                                                hue = \"experiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f0c137",
   "metadata": {},
   "source": [
    "Observe data before normalisation for a channel. The red line represents the statistical method value used for normalisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea149137",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = \"dcx\" # Modify channel as needed\n",
    "log_scale = False # Modify to True or False as needed\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (len(normMetadata)*1.5, 6))\n",
    "\n",
    "x = \"experiment\"\n",
    "y = f\"avg_intensity_{channel}\"\n",
    "data_to_plot = scData[[x, y]].copy()\n",
    "\n",
    "if log_scale:\n",
    "    data_to_plot[y] = [log10(l) for l in data_to_plot[y]]\n",
    "    \n",
    "ax = sns.violinplot(x = x, y = y, data = data_to_plot, palette = \"Set3\", bw = .2, order = list(normMetadata.keys()),\n",
    "                    ax = ax)\n",
    "    \n",
    "plt.xticks(rotation = 45,ha = \"right\")\n",
    "\n",
    "for n, exp in enumerate(normMetadata):\n",
    "    Y = log10(normMetadata[exp][y]) if log_scale else normMetadata[exp][y]\n",
    "    X = n\n",
    "    plt.plot([X-0.4,X+0.4], [Y,Y], color='r')\n",
    "\n",
    "if log_scale:\n",
    "    plt.ylabel(f\"{y} (log10)\")\n",
    "plt.tight_layout()\n",
    "#fig.savefig(f\"J:/emilio/figures/laminAC/{channel}_normalisation.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cc6300",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ce26fc",
   "metadata": {},
   "source": [
    "### Linear relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9803a2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"avg_intensity_dapi\" # Change as needed\n",
    "y = \"nuclear_area\" # Change as needed\n",
    "\n",
    "fig = sns.lmplot(x = x, \n",
    "                 y = y, \n",
    "                 data = normData,\n",
    "                 hue = \"experiment\",\n",
    "                 lowess = True,\n",
    "                 scatter = False\n",
    "                )\n",
    "#plt.xlim(10,)\n",
    "plt.ylim(0,)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fd15be",
   "metadata": {},
   "source": [
    "### Dimension Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037fe44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wkData = normData.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f79004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of observations\n",
    "obs_ = ['imageID', \n",
    "        'experiment', \n",
    "        'cellID',\n",
    "        \"x_pos\", \n",
    "        \"y_pos\",\n",
    "        \"angle\",\n",
    "        \"dcx_class\",\n",
    "        \"rfp_class\",\n",
    "        \"laminB1_class\",\n",
    "        'avg_intensity_laminB1',\n",
    "        'path2ong',\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4429773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of features\n",
    "data_cols = [\n",
    "'avg_intensity_dapi',\n",
    "'nuclear_area',\n",
    "'nuclear_perimeter',\n",
    "'major_axis',\n",
    "'minor_axis',\n",
    "'axes_ratio',\n",
    "'circularity',\n",
    "'eccentricity',\n",
    "'solidity',\n",
    "'avg_intensity_core_dapi',\n",
    "'avg_intensity_internal_ring_dapi',\n",
    "'avg_intensity_external_ring_dapi',\n",
    "#'total_intensity_core_dapi',\n",
    "#'total_intensity_internal_ring_dapi',\n",
    "#'total_intensity_external_ring_dapi',\n",
    "#'total_intensity_dapi',\n",
    "#'total_intensity_gfap',\n",
    "'avg_intensity_rfp',\n",
    "#'total_intensity_rfp',\n",
    "'avg_intensity_dcx',\n",
    "#'total_intensity_beta3',\n",
    "#'dna_peaks',\n",
    "'dna_dots',\n",
    "'dna_dots_size_median',\n",
    "'spatial_entropy',\n",
    "#'total_intensity_olig2',\n",
    "#'gfap_positive',\n",
    "#'gfap_frac_covered',\n",
    "#'rfp_positive',\n",
    "#'rfp_frac_covered',\n",
    "#'beta3_positive',\n",
    "#'beta3_frac_covered',\n",
    "#'isSingleCell',\n",
    "#'rfp_dcx_product'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50faad25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create adata object\n",
    "adata = anndata.AnnData(    \n",
    "    X = wkData[data_cols].values,\n",
    "    obs = pd.DataFrame(\n",
    "        wkData.index.to_list(), \n",
    "        columns = [\"cell_uniqID\"], \n",
    "        index = [str(n) for n in wkData.index.to_list()]\n",
    "        ),\n",
    "    var = pd.DataFrame(\n",
    "        wkData[data_cols].columns.to_list(), \n",
    "        columns = [\"feature\"], \n",
    "        index = [str(n) for n,c in enumerate(wkData[data_cols].columns)])\n",
    "    )\n",
    "\n",
    "adata.var_names = adata.var[\"feature\"].to_list()\n",
    "\n",
    "for o in tqdm(obs_):\n",
    "    if o in list(wkData.columns):\n",
    "        if \"intensity\" in o:\n",
    "            adata.obs[o] = wkData[o].to_list()\n",
    "        else:\n",
    "            adata.obs[o] = [str(l) for l in wkData[o]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d5b9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data pre-processing\n",
    "adata.X = _normalise_data(adata.X)\n",
    "sc.pp.scale(adata, max_value = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f499e3",
   "metadata": {},
   "source": [
    "#### UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e447cf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find neighbours\n",
    "sc.pp.neighbors(adata, n_neighbors = 30, use_rep = 'X', method = 'umap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb50740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run UMAP\n",
    "sc.tl.umap(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b3e7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot UMAP showing features\n",
    "fig, ax = plt.subplots(figsize = (4, 4))\n",
    "sc.pl.umap(adata, color = \"avg_intensity_dapi\", frameon = False, ax = ax,\n",
    "          size = 30,\n",
    "          )\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d545aeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find clusters\n",
    "sc.tl.leiden(adata, resolution = 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357b3a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot UMAP showing features\n",
    "fig, ax = plt.subplots(figsize = (4, 4))\n",
    "sc.pl.umap(adata, color = \"leiden\", frameon = False, ax = ax, legend_loc = \"on data\",\n",
    "          size = 30,\n",
    "          )\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ec9b82",
   "metadata": {},
   "source": [
    "#### DIFFMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a1d7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find neighbours\n",
    "sc.pp.neighbors(adata, n_neighbors = 30, use_rep = 'X', method = 'gauss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59817a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run DIFFMAP\n",
    "sc.tl.diffmap(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f494bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot DIFFMAP showing features\n",
    "fig, ax = plt.subplots(figsize = (4, 4))\n",
    "sc.pl.diffmap(adata, color = \"avg_intensity_dapi\", frameon = False, ax = ax,\n",
    "              size = 30, dimensions = [1,2]\n",
    "             )\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d928298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find clusters\n",
    "sc.tl.leiden(adata, resolution = 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511986d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot DIFFMAP showing features\n",
    "fig, ax = plt.subplots(figsize = (4, 4))\n",
    "sc.pl.diffmap(adata, color = \"leiden\", frameon = False, ax = ax, legend_loc = \"on data\",\n",
    "              size = 30, dimensions = [1,2]\n",
    "             )\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a21ad28",
   "metadata": {},
   "source": [
    "#### Pseudotime\n",
    "Choose a root cell for diffusion pseudotime:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a96447e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.uns['iroot'] = np.flatnonzero(adata.obs['leiden']  == '3')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42aa6ec9",
   "metadata": {},
   "source": [
    "Run diffusion pseudotime:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9223db6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.dpt(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770f4959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot DIFFMAP showing features\n",
    "fig, ax = plt.subplots(figsize = (4, 4))\n",
    "sc.pl.diffmap(adata, color = \"dpt_pseudotime\", frameon = False, ax = ax,\n",
    "              size = 30, dimensions = [1,2]\n",
    "             )\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea754bd7",
   "metadata": {},
   "source": [
    "#### Stacked violin plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3402e15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (5, 7))\n",
    "sc.pl.stacked_violin(adata, data_cols, groupby = 'experiment', swap_axes = True, ax = ax, dendrogram = True)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0c1634",
   "metadata": {},
   "source": [
    "#### Pseudotime - heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e93b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter order of clusters in pseudotime\n",
    "pseudotime_path = [3,4,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408160cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap - pseudotime\n",
    "sc.pl.paga_path(\n",
    "    adata, \n",
    "    pseudotime_path, \n",
    "    data_cols,\n",
    "    show_node_names = True,\n",
    "    n_avg = 50,\n",
    "    annotations = ['dpt_pseudotime'],\n",
    "    show_colorbar = True,\n",
    "    color_map = 'coolwarm',\n",
    "    groups_key = 'leiden',\n",
    "    color_maps_annotations = {'dpt_pseudotime': 'viridis'},\n",
    "    title = 'Path',\n",
    "    return_data = False,\n",
    "    normalize_to_zero_one = True,\n",
    "    show = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c79aab",
   "metadata": {},
   "source": [
    "### Save Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830c0283",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write(\"/save/path/filename.hdf5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
